{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium, os, re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from langdetect import detect\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "options = Options()\n",
    "options.headless = True\n",
    "options.add_argument(\"start-maximized\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-projection",
   "metadata": {},
   "source": [
    "## Scrape Post Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['keyword', 'title', 'author', 'body', 'time', 'date', 'status', 'votes', 'num_comments', 'num_comment_pages', 'link', 'has_status_update', 'status_message', 'status_update_date'])\n",
    "df2 = pd.DataFrame(columns=['keyword', 'title', 'comment_date', 'username', 'rank', 'text', 'likes', 'is_official_comment'])\n",
    "comments_list = []\n",
    "no_author = []\n",
    "idx = 0\n",
    "idx2 = 0\n",
    "\n",
    "link_dir = 'idea_links'\n",
    "\n",
    "# Go thorugh all files in directory\n",
    "for link_file in os.listdir(link_dir):\n",
    "    # Format keyword from file name\n",
    "    keyword = link_file.split('_')[0]\n",
    "    \n",
    "    # Open file\n",
    "    with open(os.path.join(link_dir, link_file)) as f:\n",
    "        links = f.read().split('\\n')\n",
    "        \n",
    "    # Iterate over all links in file\n",
    "    for link in tqdm(links):\n",
    "        if link == '': continue\n",
    "            \n",
    "        # Parse linkG\n",
    "        driver.get(link)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        # ONLY FOR IMPLEMENTED POSTS\n",
    "        # fetch official status\n",
    "\n",
    "        try:\n",
    "            status_component = soup.find('div', class_=\"lia-status-comment-body\")\n",
    "            has_status_update = True\n",
    "            status_message = status_component.text.strip()\n",
    "            status_date = status_message.partition('Updated on')[2].partition('\\n')[0]\n",
    "\n",
    "        except:\n",
    "            has_status_update = False\n",
    "            status_message = ''\n",
    "            status_date = ''\n",
    "\n",
    "        \n",
    "        # Retrieve the title\n",
    "        try:\n",
    "            title = ' '.join(soup.find('div', class_='lia-message-subject').getText().split())\n",
    "        except:\n",
    "            # No permission to view link\n",
    "            continue\n",
    "\n",
    "        body = ' '.join(soup.find('div', class_='lia-message-body-content').getText().split())\n",
    "\n",
    "\n",
    "        # Retrieve the number of comment pages\n",
    "        try:\n",
    "            num_comment_pages = int(soup.find('li', class_=re.compile('lia-paging-page-last lia-js-data-pageNum-[0-9]+'))['class'][-1].split('-')[-1])\n",
    "        except:\n",
    "            num_comment_pages = 1\n",
    "\n",
    "\n",
    "        ## data model for comments\n",
    "        ## array of {comment_date, comment_time, poster_username, poster_rank, comment_text, like_count, is_official_comment}\n",
    "        # Comments scraping logic\n",
    "\n",
    "        for comment_page in range(num_comment_pages):\n",
    "            comment_page_url = f'{link}/page/{comment_page + 1}#comments'\n",
    "            \n",
    "            if keyword == \"implemented\":\n",
    "                comment_page_url = link.split('?')[0] + f'/page/{comment_page + 1}#comments'\n",
    "                \n",
    "\n",
    "            driver.get(comment_page_url)\n",
    "            comment_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            comments_list = comment_soup.findAll('div', class_='lia-message-view-idea-reply-message')\n",
    "            author_rank = comment_soup.findAll('div', class_='lia-message-author-rank')\n",
    "            author_username = comment_soup.findAll('span', class_='UserName')\n",
    "            \n",
    "            print(\"Scraping \", len(comments_list) , \" comments\")\n",
    "\n",
    "            for comment in comments_list:\n",
    "                raw_text = \" \".join(comment.getText().strip().split(\"\\n\"))\n",
    "                raw_text = raw_text.replace(\"Mark as Read Mark as New     Bookmark     Permalink Print     Report Inappropriate Content\", \"\")\n",
    "                raw_text = raw_text.replace(\"\\u200e\", \"\")\n",
    "                parsed_text =  [p.strip() for p in re.split(r'\\s{2,}', raw_text) if len(p.strip()) > 0]\n",
    "                parsed_text.pop()\n",
    "\n",
    "                username = parsed_text[0]\n",
    "                rank = parsed_text[1]\n",
    "                timestamp = parsed_text[2]\n",
    "                likes = parsed_text[-1]\n",
    "\n",
    "                is_official_comment = False\n",
    "\n",
    "                if rank == 'Spotify':\n",
    "                    is_official_comment = True\n",
    "\n",
    "                if parsed_text[3].startswith(\"Status changed to\"):\n",
    "                    is_official_comment = True\n",
    "\n",
    "                comment = parsed_text[3]\n",
    "                if (len(parsed_text) > 5):\n",
    "                    copy_parsed_text = parsed_text\n",
    "                    copy_parsed_text.pop()\n",
    "                    copy_parsed_text.pop(0)\n",
    "                    copy_parsed_text.pop(0)\n",
    "                    copy_parsed_text.pop(0)\n",
    "                    comment = \" \".join(copy_parsed_text)\n",
    "                    \n",
    "                df2_new = pd.DataFrame({\n",
    "                    'keyword':keyword, 'title': title, 'comment_date': timestamp, 'username': username, 'rank': rank, 'text': comment, 'likes': likes, 'is_official_comment': is_official_comment\n",
    "                }, index=[idx2])\n",
    "                \n",
    "                # print(df2_new)\n",
    "                \n",
    "\n",
    "                df2 = pd.concat([df2, df2_new])\n",
    "                idx2 += 1\n",
    "\n",
    "\n",
    "        # Locate author section\n",
    "        try:\n",
    "            author_span = soup.find('span', {'class':\n",
    "                                             ['lia-message-byline lia-message-byline-author-date lia-component-byline-author-date lia-component-message-view-widget-byline-author-date',\n",
    "                                              re.compile('lia-user-name lia-user-rank-.* lia-component-message-view-widget-author-username'),\n",
    "                                             ]})\n",
    "\n",
    "            # If there is an author, find here\n",
    "            try:\n",
    "                author = author_span.find('a', class_='lia-link-navigation lia-page-link lia-user-name-link')['aria-label']\n",
    "                author = author.split('View Profile of ')[1]\n",
    "            # Otherwise, author was removed. Value is 'user-removed'\n",
    "            except:\n",
    "                author = author_span.find('span', class_='anon-user').getText()\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Locate date and time\n",
    "        try:\n",
    "            date = soup.find('span', class_='local-date').getText()\n",
    "            time = soup.find('span', class_='local-time').getText()\n",
    "        except:\n",
    "            stamp = soup.find('span', class_='local-friendly-date')['title']\n",
    "            date = stamp.split()[0]\n",
    "            time = stamp.split()[1] + ' ' + stamp.split()[2]\n",
    "        \n",
    "        # Locate post status\n",
    "        try:\n",
    "            status_span = soup.find('span', class_=re.compile('MessageStatus lia-status lia-status-idea-.* lia-status-completed lia-component-message-status lia-component-message-view-widget-message-status'))\n",
    "                                                    \n",
    "            status = status_span.find('a', class_='lia-link-navigation message-status-link').getText()\n",
    "        except:\n",
    "            status = soup.find('span', class_='lia-img-message-type-solved lia-fa-message lia-fa-type lia-fa-solved lia-fa')\n",
    "            if status != None:\n",
    "                status = status['title']\n",
    "\n",
    "        # If there is a vote count, find it\n",
    "        try:\n",
    "            votes = soup.find('span', class_='MessageKudosCount lia-component-kudos-widget-message-kudos-count').getText()\n",
    "            votes = int(votes.replace(',', ''))\n",
    "        # Otherwise, set votes to -1\n",
    "        except:\n",
    "            votes = -1\n",
    "\n",
    "        # Update dataframe with new data\n",
    "        df_new = pd.DataFrame({\n",
    "            'keyword':keyword, 'title': title, 'author': author, 'body': body, 'time': time, 'date': date,\n",
    "            'status': keyword, 'votes': votes, 'num_comments':num_comment_pages*10, 'num_comment_pages':num_comment_pages, 'link': link,\n",
    "            'has_status_update': has_status_update, 'status_message': status_message, 'status_update_date': status_date\n",
    "        }, index=[idx])\n",
    "\n",
    "        df = pd.concat([df, df_new])\n",
    "\n",
    "        idx = idx + 1\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-lawyer",
   "metadata": {},
   "source": [
    "#### Filter out non-english comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-thing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lang(row):\n",
    "    try:\n",
    "        return detect(row['body'])\n",
    "    except:\n",
    "        print(row['link'])\n",
    "        return None\n",
    "    \n",
    "df['lang'] = df.apply(lambda row: get_lang(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['lang'] == 'en']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-activation",
   "metadata": {},
   "source": [
    "# Write to file\n",
    "\n",
    "Dataframe contains one column per useful attribute. If there is no status, the value is None. If there is no vote count, the value is -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-construction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "df = df.drop_duplicates(subset='body')\n",
    "df.to_csv('posts-en-' + today.strftime(\"%b-%d-%Y\") + '.csv')\n",
    "df2.to_csv('comments-en-' + today.strftime(\"%b-%d-%Y\") + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40405cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb654c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dfa5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcae37c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1de105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c791107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a614e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c10a28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
