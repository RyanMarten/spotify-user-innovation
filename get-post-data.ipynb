{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "australian-bernard",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/8x6xycw50x793r_4z9sbn7hw0000gn/T/ipykernel_11036/2704787584.py:12: DeprecationWarning: headless property is deprecated, instead use add_argument('--headless') or add_argument('--headless=new')\n",
      "  options.headless = True\n",
      "[WDM] - Downloading: 100%|██████████| 8.04M/8.04M [00:04<00:00, 1.75MB/s]\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: Service /Users/aruna/.wdm/drivers/chromedriver/mac_arm64/112.0.5615.49/chromedriver unexpectedly exited. Status code was: -9\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m options\u001b[39m.\u001b[39mheadless \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     13\u001b[0m options\u001b[39m.\u001b[39madd_argument(\u001b[39m\"\u001b[39m\u001b[39mstart-maximized\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m driver \u001b[39m=\u001b[39m webdriver\u001b[39m.\u001b[39;49mChrome(service\u001b[39m=\u001b[39;49mService(ChromeDriverManager()\u001b[39m.\u001b[39;49minstall()), options\u001b[39m=\u001b[39;49moptions)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/selenium/webdriver/chrome/webdriver.py:84\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, service, keep_alive)\u001b[0m\n\u001b[1;32m     81\u001b[0m     service \u001b[39m=\u001b[39m Service(executable_path, port, service_args, service_log_path)\n\u001b[1;32m     82\u001b[0m service\u001b[39m.\u001b[39mpath \u001b[39m=\u001b[39m DriverFinder\u001b[39m.\u001b[39mget_path(service, options)\n\u001b[0;32m---> 84\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     85\u001b[0m     DesiredCapabilities\u001b[39m.\u001b[39;49mCHROME[\u001b[39m\"\u001b[39;49m\u001b[39mbrowserName\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     86\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mgoog\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     87\u001b[0m     port,\n\u001b[1;32m     88\u001b[0m     options,\n\u001b[1;32m     89\u001b[0m     service_args,\n\u001b[1;32m     90\u001b[0m     desired_capabilities,\n\u001b[1;32m     91\u001b[0m     service_log_path,\n\u001b[1;32m     92\u001b[0m     service,\n\u001b[1;32m     93\u001b[0m     keep_alive,\n\u001b[1;32m     94\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/selenium/webdriver/chromium/webdriver.py:101\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[0;34m(self, browser_name, vendor_prefix, port, options, service_args, desired_capabilities, service_log_path, service, keep_alive)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mservice cannot be None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice \u001b[39m=\u001b[39m service\n\u001b[0;32m--> 101\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mservice\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m    103\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m    105\u001b[0m         command_executor\u001b[39m=\u001b[39mChromiumRemoteConnection(\n\u001b[1;32m    106\u001b[0m             remote_server_addr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice\u001b[39m.\u001b[39mservice_url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m         options\u001b[39m=\u001b[39moptions,\n\u001b[1;32m    113\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/selenium/webdriver/common/service.py:100\u001b[0m, in \u001b[0;36mService.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     99\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49massert_process_still_running()\n\u001b[1;32m    101\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_connectable():\n\u001b[1;32m    102\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/selenium/webdriver/common/service.py:113\u001b[0m, in \u001b[0;36mService.assert_process_still_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m return_code \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess\u001b[39m.\u001b[39mpoll()\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m return_code:\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mraise\u001b[39;00m WebDriverException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mService \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path\u001b[39m}\u001b[39;00m\u001b[39m unexpectedly exited. Status code was: \u001b[39m\u001b[39m{\u001b[39;00mreturn_code\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: Service /Users/aruna/.wdm/drivers/chromedriver/mac_arm64/112.0.5615.49/chromedriver unexpectedly exited. Status code was: -9\n"
     ]
    }
   ],
   "source": [
    "import selenium, os, re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from langdetect import detect\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "options = Options()\n",
    "options.headless = True\n",
    "options.add_argument(\"start-maximized\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-projection",
   "metadata": {},
   "source": [
    "## Scrape Post Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "df = pd.DataFrame(columns=['keyword', 'title', 'author', 'body', 'time', 'date', 'status', 'votes', 'num_comments', 'num_comment_pages', 'link', 'has_status_update', 'status_message', 'status_update_date'])\n",
    "df2 = pd.DataFrame(columns=['keyword', 'title', 'comment_date', 'username', 'rank', 'text', 'likes', 'is_official_comment'])\n",
    "comments_list = []\n",
    "no_author = []\n",
    "idx = 0\n",
    "idx2 = 68881\n",
    "\n",
    "link_dir = 'idea_links'\n",
    "\n",
    "# Go thorugh all files in directory\n",
    "for link_file in os.listdir(link_dir):\n",
    "    if link_file == 'implemented_post_links.csv':\n",
    "        continue\n",
    "\n",
    "    # Format keyword from file name\n",
    "    keyword = link_file.split('_')[0]\n",
    "    \n",
    "    # Open file\n",
    "    with open(os.path.join(link_dir, link_file)) as f:\n",
    "        links = f.read().split('\\n')\n",
    "        \n",
    "    # Iterate over all links in file\n",
    "    for link in tqdm(links):\n",
    "        if link == '': continue\n",
    "        if idx < 135: \n",
    "            idx = idx + 1\n",
    "            continue\n",
    "            \n",
    "        # Parse linkG\n",
    "        driver.get(link)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        # ONLY FOR IMPLEMENTED POSTS\n",
    "        # fetch official status\n",
    "\n",
    "        try:\n",
    "            status_component = soup.find('div', class_=\"lia-status-comment-body\").getText()\n",
    "            has_status_update = True\n",
    "            status_component = status_component.replace(\"\\t\", \" \")\n",
    "            status_component = status_component.replace(\"\\n\", \" \")\n",
    "            status_message = status_component\n",
    "            status_date = status_message.split()[2]\n",
    "            # print(status_date)\n",
    "\n",
    "        except:\n",
    "            has_status_update = False\n",
    "            status_message = ''\n",
    "            status_date = ''\n",
    "\n",
    "        \n",
    "        # Retrieve the title\n",
    "        try:\n",
    "            title = ' '.join(soup.find('div', class_='lia-message-subject').getText().split())\n",
    "        except:\n",
    "            # No permission to view link\n",
    "            continue\n",
    "\n",
    "        body = ' '.join(soup.find('div', class_='lia-message-body-content').getText().split())\n",
    "\n",
    "\n",
    "        # Retrieve the number of comment pages\n",
    "        try:\n",
    "            num_comment_pages = int(soup.find('li', class_=re.compile('lia-paging-page-last lia-js-data-pageNum-[0-9]+'))['class'][-1].split('-')[-1])\n",
    "        except:\n",
    "            num_comment_pages = 1\n",
    "\n",
    "\n",
    "        ## data model for comments\n",
    "        ## array of {comment_date, comment_time, poster_username, poster_rank, comment_text, like_count, is_official_comment}\n",
    "        # Comments scraping logic\n",
    "\n",
    "        for comment_page in range(num_comment_pages):\n",
    "            comment_page_url = f'{link}/page/{comment_page + 1}#comments'\n",
    "            \n",
    "            if keyword == \"implemented\":\n",
    "                comment_page_url = link.split('?')[0] + f'/page/{comment_page + 1}#comments'\n",
    "                \n",
    "\n",
    "            driver.get(comment_page_url)\n",
    "            comment_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            comments_list = comment_soup.findAll('div', class_='lia-message-view-idea-reply-message')\n",
    "            author_rank = comment_soup.findAll('div', class_='lia-message-author-rank')\n",
    "            author_username = comment_soup.findAll('span', class_='UserName')\n",
    "            \n",
    "            print(\"Scraping \", len(comments_list) , \" comments\")\n",
    "\n",
    "            for comment in comments_list:\n",
    "                raw_text = \" \".join(comment.getText().strip().split(\"\\n\"))\n",
    "                raw_text = raw_text.replace(\"Mark as Read Mark as New     Bookmark     Permalink Print     Report Inappropriate Content\", \"\")\n",
    "                raw_text = raw_text.replace(\"\\u200e\", \"\")\n",
    "                parsed_text =  [p.strip() for p in re.split(r'\\s{2,}', raw_text) if len(p.strip()) > 0]\n",
    "                parsed_text.pop()\n",
    "\n",
    "                username = parsed_text[0]\n",
    "                rank = parsed_text[1]\n",
    "                timestamp = parsed_text[2]\n",
    "                likes = parsed_text[-1]\n",
    "\n",
    "                is_official_comment = False\n",
    "\n",
    "                if rank == 'Spotify':\n",
    "                    is_official_comment = True\n",
    "\n",
    "                try:\n",
    "                    if parsed_text[3].startswith(\"Status changed to\"):\n",
    "                        is_official_comment = True\n",
    "                    \n",
    "                    comment = parsed_text[3]\n",
    "\n",
    "                    if (len(parsed_text) > 5):\n",
    "                        copy_parsed_text = parsed_text\n",
    "                        copy_parsed_text.pop()\n",
    "                        copy_parsed_text.pop(0)\n",
    "                        copy_parsed_text.pop(0)\n",
    "                        copy_parsed_text.pop(0)\n",
    "                        comment = \" \".join(copy_parsed_text)\n",
    "                        \n",
    "                    df2_new = pd.DataFrame({\n",
    "                        'keyword':keyword, 'title': title, 'comment_date': timestamp, 'username': username, 'rank': rank, 'text': comment, 'likes': likes, 'is_official_comment': is_official_comment\n",
    "                    }, index=[idx2])\n",
    "                    \n",
    "                    df2_new.to_csv('all-comments-' + today.strftime(\"%b-%d-%Y\") + '.csv', mode='a', header=False)\n",
    "\n",
    "                except:\n",
    "                    print(\"Unable to parse comment!\")\n",
    "                    print(parsed_text)\n",
    "                \n",
    "                df2 = pd.concat([df2, df2_new])\n",
    "                idx2 += 1\n",
    "\n",
    "\n",
    "        # Locate author section\n",
    "        try:\n",
    "            author_span = soup.find('span', {'class':\n",
    "                                             ['lia-message-byline lia-message-byline-author-date lia-component-byline-author-date lia-component-message-view-widget-byline-author-date',\n",
    "                                              re.compile('lia-user-name lia-user-rank-.* lia-component-message-view-widget-author-username'),\n",
    "                                             ]})\n",
    "\n",
    "            # If there is an author, find here\n",
    "            try:\n",
    "                author = author_span.find('a', class_='lia-link-navigation lia-page-link lia-user-name-link')['aria-label']\n",
    "                author = author.split('View Profile of ')[1]\n",
    "            # Otherwise, author was removed. Value is 'user-removed'\n",
    "            except:\n",
    "                author = author_span.find('span', class_='anon-user').getText()\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Locate date and time\n",
    "        try:\n",
    "            date = soup.find('span', class_='local-date').getText()\n",
    "            time = soup.find('span', class_='local-time').getText()\n",
    "        except:\n",
    "            stamp = soup.find('span', class_='local-friendly-date')['title']\n",
    "            date = stamp.split()[0]\n",
    "            time = stamp.split()[1] + ' ' + stamp.split()[2]\n",
    "        \n",
    "        # Locate post status\n",
    "        try:\n",
    "            status_span = soup.find('span', class_=re.compile('MessageStatus lia-status lia-status-idea-.* lia-status-completed lia-component-message-status lia-component-message-view-widget-message-status'))\n",
    "                                                    \n",
    "            status = status_span.find('a', class_='lia-link-navigation message-status-link').getText()\n",
    "        except:\n",
    "            status = soup.find('span', class_='lia-img-message-type-solved lia-fa-message lia-fa-type lia-fa-solved lia-fa')\n",
    "            if status != None:\n",
    "                status = status['title']\n",
    "\n",
    "        # If there is a vote count, find it\n",
    "        try:\n",
    "            votes = soup.find('span', class_='MessageKudosCount lia-component-kudos-widget-message-kudos-count').getText()\n",
    "            votes = int(votes.replace(',', ''))\n",
    "        # Otherwise, set votes to -1\n",
    "        except:\n",
    "            votes = -1\n",
    "\n",
    "        # Update dataframe with new data\n",
    "        df_new = pd.DataFrame({\n",
    "            'keyword':keyword, 'title': title, 'author': author, 'body': body, 'time': time, 'date': date,\n",
    "            'status': keyword, 'votes': votes, 'num_comments':num_comment_pages*10, 'num_comment_pages':num_comment_pages, 'link': link,\n",
    "            'has_status_update': has_status_update, 'status_message': status_message, 'status_update_date': status_date\n",
    "        }, index=[idx])\n",
    "\n",
    "        df = pd.concat([df, df_new])\n",
    "\n",
    "        idx = idx + 1\n",
    "\n",
    "        df_new.to_csv('all-posts-' + today.strftime(\"%b-%d-%Y\") + '.csv', mode='a', header=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-lawyer",
   "metadata": {},
   "source": [
    "#### Filter out non-english comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-thing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lang(row):\n",
    "    try:\n",
    "        return detect(row['body'])\n",
    "    except:\n",
    "        print(row['link'])\n",
    "        return None\n",
    "    \n",
    "df['lang'] = df.apply(lambda row: get_lang(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['lang'] == 'en']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-activation",
   "metadata": {},
   "source": [
    "# Write to file\n",
    "\n",
    "Dataframe contains one column per useful attribute. If there is no status, the value is None. If there is no vote count, the value is -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-construction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "df = df.drop_duplicates(subset='body')\n",
    "df.to_csv('posts-en-' + today.strftime(\"%b-%d-%Y\") + '.csv')\n",
    "df2.to_csv('comments-en-' + today.strftime(\"%b-%d-%Y\") + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40405cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb654c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dfa5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcae37c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1de105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c791107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a614e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c10a28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
